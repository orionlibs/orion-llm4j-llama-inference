orion-llm4j.temperature=0.1
orion-llm4j.randomness=0.95
orion-llm4j.maximum.tokens.to.produce=512
orion-llm4j.interactive.chat=false
orion-llm4j.llm.model.path=src/test/resources/io/github/orionlibs/orion_llm4j/models/Meta-Llama-3.1-8B-Instruct-Q4_0.gguf